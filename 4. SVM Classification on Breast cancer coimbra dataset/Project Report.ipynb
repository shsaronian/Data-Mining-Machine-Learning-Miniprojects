{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project we will perform svm with different kernels on a UCI machine learning repository dataset called \"Breast Cancer Coimbra Data Set\". There are 10 quantitative attributes: Age,BMI,Glucose,Insulin,HOMA,Leptin,Adiponectin,Resistin,and MCP-1.\n",
    "There is also an 11th feature which is nominal called Label,which indicates if a patient is healthy or has cancer. There are 116 instances in this dataset. \n",
    "To begin,first we'll import the necessary packages for different parts of the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report , confusion_matrix \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll import the dataset using pandas' read_csv method, seperate the 10 features from the labels,save the features in x variable and the labels in y and perform two train test splits with train size=0.7, validation size=0.15 and test size=0.15 to obtain train,test,and validation sets necessary for the project.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('dataR2.csv')\n",
    "x=data.iloc[:,:-1].values\n",
    "y=data.iloc[:,-1].values\n",
    "X_train1, X_test, y_train1, y_test = train_test_split(x, y, test_size=0.15, random_state=0)\n",
    "X_train,X_valid,y_train,y_valid = train_test_split(X_train1,y_train1,test_size=0.15,random_state=0 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now,we'll use sklearn's SVC class,build an SVC object, and fit the model on our train set. We'll use three different kernels: Polynomial,Gaussian,and Sigmoid.For each kernel,we'll use the test set to predict the samples, then we'll calculate the confusion matrix and the evaluation metrics accuracy,precision,recall,and F1-score using sklearn's metric library.\n",
    "Finally, we'll compare these metrics for different kernels against each other and choose the kernel that has the highest overall result. For fairness and better comparison, we'll set the value of the soft margin parameter C to 1 in every kernel and the gamma parameter to 0.0001 in Gaussian and Sigmoid kernels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Polynomial Kernel</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we'll implement svm using polynomial kernel and fit the model to train set. We'll set the degree to 8(because the default degree value in sklearn(3)causes the code to run very slowly). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=8, gamma='auto_deprecated',\n",
       "    kernel='poly', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svclassifier = SVC(kernel='poly',degree=8,C=1)\n",
    "svclassifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to use the test set to make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real y values:  [1 2 2 1 1 2 2 2 2 2 1 1 2 1 1 2 1 2]\n",
      "Predicted y values:  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "y_pred = svclassifier.predict(X_test)\n",
    "print('Real y values: ', y_test)\n",
    "print('Predicted y values: ', y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, some labels in test set are 1 and some are 2, but polynomial kernel has falsely predicted each label to be 1.To get a better view of the performance, we'll calculate the confusion matrix,accuracy,precision,recall,and F1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 8  0]\n",
      " [10  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.44      1.00      0.62         8\n",
      "           2       0.00      0.00      0.00        10\n",
      "\n",
      "    accuracy                           0.44        18\n",
      "   macro avg       0.22      0.50      0.31        18\n",
      "weighted avg       0.20      0.44      0.27        18\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's repeat the process for Gaussian(rbf) and Sigmoid kernels and compare the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Gaussian Kernel</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing svm with rbf kernel and fitting on train set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma=0.0001, kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svclassifier = SVC(kernel='rbf',gamma=0.0001,C=1)\n",
    "svclassifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real y values:  [1 2 2 1 1 2 2 2 2 2 1 1 2 1 1 2 1 2]\n",
      "Predicted y values:  [2 2 1 2 2 2 2 2 2 2 1 1 2 1 2 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "y_pred = svclassifier.predict(X_test)\n",
    "print('Real y values: ', y_test)\n",
    "print('Predicted y values: ', y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that this kernel performed better. Let's take a closer look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[4 4]\n",
      " [3 7]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.50      0.53         8\n",
      "           2       0.64      0.70      0.67        10\n",
      "\n",
      "    accuracy                           0.61        18\n",
      "   macro avg       0.60      0.60      0.60        18\n",
      "weighted avg       0.61      0.61      0.61        18\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Sigmoid Kernel</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the data with sigmoid kernel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma=0.0001, kernel='sigmoid',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svclassifier = SVC(kernel='sigmoid',gamma=0.0001,C=1)\n",
    "svclassifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real y values:  [1 2 2 1 1 2 2 2 2 2 1 1 2 1 1 2 1 2]\n",
      "Predicted y values:  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "y_pred = svclassifier.predict(X_test)\n",
    "print('Real y values: ', y_test)\n",
    "print('Predicted y values: ', y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the Polynomial kernel, this kernel falsely predicted every label to be 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 0  8]\n",
      " [ 0 10]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         8\n",
      "           2       0.56      1.00      0.71        10\n",
      "\n",
      "    accuracy                           0.56        18\n",
      "   macro avg       0.28      0.50      0.36        18\n",
      "weighted avg       0.31      0.56      0.40        18\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's time to make comparisons on the evaluation results and choose the best kernel. We'll begin with the Confusion Matrices. The matrix for polynomial kernel has 8 true positives and 10 false positives. So, 8 labels were predicted correctly and 10 labels were predicted falsely.That means that the kernel has correctly detected 8 patients to be healthy,but has falsely detected 10 patients as healthy while they had cancer.\n",
    "The matrix for sigmoid kernel has 8 false negatives and 10 true negatives.So, 10 labels were predicted correctly and 8 labels were predicted falsely. That means that the kernel has falsely detected 8 patients to have cancer while they were healthy,and has correctly detected 10 patients to be healthy.\n",
    "So, sigmoid has performed better than polynomial.\n",
    "Lastly, the rbf matrix has 4 true positives and 7 true negatives and 4 false negatives and 3 false positives. That means that 11 labels were predicted correctly and 7 were predicted falsely. So the Gaussian kernel predicted 1 more label correctly compared to sigmoid kernel.\n",
    "So, Gaussian has performed better than sigmoid.\n",
    "In terms of accuracy score, again we see that polynomial kernel has the lowest accuracy(0.44),sigmoid is better than polynomial(0.55),and gaussian has the highest accuracy(0.61).\n",
    "For precision,recall,and F1-scores we will compare the macro average.\n",
    "In terms of precision,polynomial kernel has the lowest precision(0.22),sigmoid is better(0.28),and gaussian has the highest precision(0.6).\n",
    "In terms of recall,polynomial and sigmoid kernels have equal recall(0.5),and gaussian has the highest recall(0.6).\n",
    "In terms of F1-score,polynomial kernel has the lowest score(0.31),sigmoid is better(0.36),and gaussian has the highest score(0.6).\n",
    "\n",
    "So with all the comparisons being made on all evaluation metrics, the Gaussian kernel has the best performance among all the kernels as it has the highest evaluation scores. Therefore we shall proceed with it through the entire project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next part asks us to implement svm with the ideal kernel, each time changing the soft margin hyper parameter C and see what difference it makes to the evaluation metrics each time. \n",
    "First,we'll specify some C values and store them in an array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Different C values:  [1.e-04 1.e-03 1.e-02 1.e-01 1.e+00 1.e+01 1.e+02 1.e+03]\n"
     ]
    }
   ],
   "source": [
    "C = np.array([0.0001,0.001,0.01,0.1,1, 10, 100, 1000])\n",
    "print('Different C values: ',C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, for each C value,we'll fit svm with Gaussian kernel on train set,predict the values using the test set,and calculate the confusion matrix,accuracy,precision,recall,and F1-score metrics. In the end,we'll compare the metrics for different C values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=  0.0001\n",
      "Real y values:  [1 2 2 1 1 2 2 2 2 2 1 1 2 1 1 2 1 2]\n",
      "Predicted y values:  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "Confusion Matrix: \n",
      "[[ 0  8]\n",
      " [ 0 10]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         8\n",
      "           2       0.56      1.00      0.71        10\n",
      "\n",
      "    accuracy                           0.56        18\n",
      "   macro avg       0.28      0.50      0.36        18\n",
      "weighted avg       0.31      0.56      0.40        18\n",
      "\n",
      "C=  0.001\n",
      "Real y values:  [1 2 2 1 1 2 2 2 2 2 1 1 2 1 1 2 1 2]\n",
      "Predicted y values:  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "Confusion Matrix: \n",
      "[[ 0  8]\n",
      " [ 0 10]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         8\n",
      "           2       0.56      1.00      0.71        10\n",
      "\n",
      "    accuracy                           0.56        18\n",
      "   macro avg       0.28      0.50      0.36        18\n",
      "weighted avg       0.31      0.56      0.40        18\n",
      "\n",
      "C=  0.01\n",
      "Real y values:  [1 2 2 1 1 2 2 2 2 2 1 1 2 1 1 2 1 2]\n",
      "Predicted y values:  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "Confusion Matrix: \n",
      "[[ 0  8]\n",
      " [ 0 10]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         8\n",
      "           2       0.56      1.00      0.71        10\n",
      "\n",
      "    accuracy                           0.56        18\n",
      "   macro avg       0.28      0.50      0.36        18\n",
      "weighted avg       0.31      0.56      0.40        18\n",
      "\n",
      "C=  0.1\n",
      "Real y values:  [1 2 2 1 1 2 2 2 2 2 1 1 2 1 1 2 1 2]\n",
      "Predicted y values:  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "Confusion Matrix: \n",
      "[[ 0  8]\n",
      " [ 0 10]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         8\n",
      "           2       0.56      1.00      0.71        10\n",
      "\n",
      "    accuracy                           0.56        18\n",
      "   macro avg       0.28      0.50      0.36        18\n",
      "weighted avg       0.31      0.56      0.40        18\n",
      "\n",
      "C=  1.0\n",
      "Real y values:  [1 2 2 1 1 2 2 2 2 2 1 1 2 1 1 2 1 2]\n",
      "Predicted y values:  [2 2 1 2 2 2 2 2 2 2 1 1 2 1 2 1 1 1]\n",
      "Confusion Matrix: \n",
      "[[4 4]\n",
      " [3 7]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.50      0.53         8\n",
      "           2       0.64      0.70      0.67        10\n",
      "\n",
      "    accuracy                           0.61        18\n",
      "   macro avg       0.60      0.60      0.60        18\n",
      "weighted avg       0.61      0.61      0.61        18\n",
      "\n",
      "C=  10.0\n",
      "Real y values:  [1 2 2 1 1 2 2 2 2 2 1 1 2 1 1 2 1 2]\n",
      "Predicted y values:  [1 2 1 1 2 1 2 2 2 1 1 2 2 1 2 2 1 1]\n",
      "Confusion Matrix: \n",
      "[[5 3]\n",
      " [4 6]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.62      0.59         8\n",
      "           2       0.67      0.60      0.63        10\n",
      "\n",
      "    accuracy                           0.61        18\n",
      "   macro avg       0.61      0.61      0.61        18\n",
      "weighted avg       0.62      0.61      0.61        18\n",
      "\n",
      "C=  100.0\n",
      "Real y values:  [1 2 2 1 1 2 2 2 2 2 1 1 2 1 1 2 1 2]\n",
      "Predicted y values:  [1 2 2 1 1 1 2 2 2 2 1 2 2 1 1 2 1 1]\n",
      "Confusion Matrix: \n",
      "[[7 1]\n",
      " [2 8]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.88      0.82         8\n",
      "           2       0.89      0.80      0.84        10\n",
      "\n",
      "    accuracy                           0.83        18\n",
      "   macro avg       0.83      0.84      0.83        18\n",
      "weighted avg       0.84      0.83      0.83        18\n",
      "\n",
      "C=  1000.0\n",
      "Real y values:  [1 2 2 1 1 2 2 2 2 2 1 1 2 1 1 2 1 2]\n",
      "Predicted y values:  [1 2 2 1 2 2 2 2 2 2 2 1 2 2 1 2 1 1]\n",
      "Confusion Matrix: \n",
      "[[5 3]\n",
      " [1 9]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.62      0.71         8\n",
      "           2       0.75      0.90      0.82        10\n",
      "\n",
      "    accuracy                           0.78        18\n",
      "   macro avg       0.79      0.76      0.77        18\n",
      "weighted avg       0.79      0.78      0.77        18\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for c in C:\n",
    "    svclassifier = SVC(kernel='rbf',gamma=0.0001,C=c)\n",
    "    svclassifier.fit(X_train,y_train)\n",
    "    y_pred = svclassifier.predict(X_test)\n",
    "    print(\"C= \",c) \n",
    "    print('Real y values: ',y_test)\n",
    "    print('Predicted y values: ',y_pred)\n",
    "    print('Confusion Matrix: ')\n",
    "    print(confusion_matrix(y_test,y_pred))\n",
    "    print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the results we obtain the fact that increasing the soft margin value from 0.0001 up to 100 improves the accuracy,precision,recall,and F1 scores and decreases the number of falsely predicted labels in the confusion matrix. However, increasing the C from 100 to 1000 decreases the scores and increases the number of falsely predicted values in the confusion matrix which suggests that we may be witnessing an overfit. Overall, increasing the C parameter improves the model's performance and increases the overall accuracy which is visible in the evaluation metrics as well.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next part asks us to change the train set size each time and see how the evaluation metrics vary.\n",
    "To do that, we'll store different test set sizes in an array and use a loop to perform the train test validation split with different train sizes each time(Train sizes of 0.1 to 0.9).For each iteration in the loop,we'll fit svm with Gaussian kernel on the train set,predict the samples using the test set and calculate the evaluation metrics.We'll then compare the metrics obtained from each iteration to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size=  0.1\n",
      "Real y values:  [1 2 2 1 1 2 2 2 2 2 1 1 2 1 1 2 1 2 2 2 1 1 1 2 2 2 2 2 1 2 1 1 1 1 1 2 2\n",
      " 2 2 2 2 2 1 1 1 2 2 2 2 1 1 2 1]\n",
      "Predicted y values:  [1 1 2 2 2 2 1 2 1 1 2 2 1 2 1 2 2 1 1 1 1 2 2 2 1 1 1 1 2 2 2 1 2 1 2 2 2\n",
      " 1 1 1 2 2 2 1 1 1 1 1 1 2 2 1 1]\n",
      "Confusion Matrix: \n",
      "[[ 8 15]\n",
      " [20 10]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.29      0.35      0.31        23\n",
      "           2       0.40      0.33      0.36        30\n",
      "\n",
      "    accuracy                           0.34        53\n",
      "   macro avg       0.34      0.34      0.34        53\n",
      "weighted avg       0.35      0.34      0.34        53\n",
      "\n",
      "train size=  0.2\n",
      "Real y values:  [1 2 2 1 1 2 2 2 2 2 1 1 2 1 1 2 1 2 2 2 1 1 1 2 2 2 2 2 1 2 1 1 1 1 1 2 2\n",
      " 2 2 2 2 2 1 1 1 2 2]\n",
      "Predicted y values:  [2 2 2 1 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2\n",
      " 1 2 2 2 2 2 2 2 1 2]\n",
      "Confusion Matrix: \n",
      "[[ 2 18]\n",
      " [ 3 24]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.40      0.10      0.16        20\n",
      "           2       0.57      0.89      0.70        27\n",
      "\n",
      "    accuracy                           0.55        47\n",
      "   macro avg       0.49      0.49      0.43        47\n",
      "weighted avg       0.50      0.55      0.47        47\n",
      "\n",
      "train size=  0.3\n",
      "Real y values:  [1 2 2 1 1 2 2 2 2 2 1 1 2 1 1 2 1 2 2 2 1 1 1 2 2 2 2 2 1 2 1 1 1 1 1 2 2\n",
      " 2 2 2 2]\n",
      "Predicted y values:  [2 2 2 1 2 2 1 2 2 1 2 1 2 2 2 1 1 2 2 2 1 2 2 2 2 2 2 2 1 2 2 2 2 2 1 2 1\n",
      " 1 2 2 2]\n",
      "Confusion Matrix: \n",
      "[[ 6 11]\n",
      " [ 5 19]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.35      0.43        17\n",
      "           2       0.63      0.79      0.70        24\n",
      "\n",
      "    accuracy                           0.61        41\n",
      "   macro avg       0.59      0.57      0.57        41\n",
      "weighted avg       0.60      0.61      0.59        41\n",
      "\n",
      "train size=  0.4\n",
      "Real y values:  [1 2 2 1 1 2 2 2 2 2 1 1 2 1 1 2 1 2 2 2 1 1 1 2 2 2 2 2 1 2 1 1 1 1 1]\n",
      "Predicted y values:  [2 2 2 1 1 2 2 2 2 2 2 1 2 2 1 2 2 2 2 2 1 2 2 2 2 2 1 1 2 2 2 2 2 2 2]\n",
      "Confusion Matrix: \n",
      "[[ 5 12]\n",
      " [ 2 16]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.29      0.42        17\n",
      "           2       0.57      0.89      0.70        18\n",
      "\n",
      "    accuracy                           0.60        35\n",
      "   macro avg       0.64      0.59      0.56        35\n",
      "weighted avg       0.64      0.60      0.56        35\n",
      "\n",
      "train size=  0.5\n",
      "Real y values:  [1 2 2 1 1 2 2 2 2 2 1 1 2 1 1 2 1 2 2 2 1 1 1 2 2 2 2 2 1]\n",
      "Predicted y values:  [1 2 1 1 1 2 1 2 1 1 2 1 2 2 1 2 1 1 2 2 1 1 2 2 2 2 2 1 2]\n",
      "Confusion Matrix: \n",
      "[[ 8  4]\n",
      " [ 6 11]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.67      0.62        12\n",
      "           2       0.73      0.65      0.69        17\n",
      "\n",
      "    accuracy                           0.66        29\n",
      "   macro avg       0.65      0.66      0.65        29\n",
      "weighted avg       0.67      0.66      0.66        29\n",
      "\n",
      "train size=  0.6\n",
      "Real y values:  [1 2 2 1 1 2 2 2 2 2 1 1 2 1 1 2 1 2 2 2 1 1 1 2]\n",
      "Predicted y values:  [2 2 2 1 1 2 2 2 1 2 2 2 2 2 1 1 1 1 2 2 1 1 2 2]\n",
      "Confusion Matrix: \n",
      "[[ 6  5]\n",
      " [ 3 10]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.55      0.60        11\n",
      "           2       0.67      0.77      0.71        13\n",
      "\n",
      "    accuracy                           0.67        24\n",
      "   macro avg       0.67      0.66      0.66        24\n",
      "weighted avg       0.67      0.67      0.66        24\n",
      "\n",
      "train size=  0.7\n",
      "Real y values:  [1 2 2 1 1 2 2 2 2 2 1 1 2 1 1 2 1 2]\n",
      "Predicted y values:  [1 2 2 1 1 1 2 2 2 2 1 2 2 1 1 2 1 1]\n",
      "Confusion Matrix: \n",
      "[[7 1]\n",
      " [2 8]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.88      0.82         8\n",
      "           2       0.89      0.80      0.84        10\n",
      "\n",
      "    accuracy                           0.83        18\n",
      "   macro avg       0.83      0.84      0.83        18\n",
      "weighted avg       0.84      0.83      0.83        18\n",
      "\n",
      "train size=  0.8\n",
      "Real y values:  [1 2 2 1 1 2 2 2 2 2 1 1]\n",
      "Predicted y values:  [2 2 2 1 1 2 2 2 1 2 1 2]\n",
      "Confusion Matrix: \n",
      "[[3 2]\n",
      " [1 6]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.60      0.67         5\n",
      "           2       0.75      0.86      0.80         7\n",
      "\n",
      "    accuracy                           0.75        12\n",
      "   macro avg       0.75      0.73      0.73        12\n",
      "weighted avg       0.75      0.75      0.74        12\n",
      "\n",
      "train size=  0.9\n",
      "Real y values:  [1 2 2 1 1 2]\n",
      "Predicted y values:  [2 2 2 1 2 2]\n",
      "Confusion Matrix: \n",
      "[[1 2]\n",
      " [0 3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.33      0.50         3\n",
      "           2       0.60      1.00      0.75         3\n",
      "\n",
      "    accuracy                           0.67         6\n",
      "   macro avg       0.80      0.67      0.62         6\n",
      "weighted avg       0.80      0.67      0.62         6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_size = np.array([0.45,0.4,0.35,0.3,0.25,0.2,0.15,0.1,0.05])\n",
    "for t in test_size:\n",
    "    X_train1, X_test, y_train1, y_test = train_test_split(x, y, test_size= t, random_state=0)\n",
    "    X_train,X_valid,y_train,y_valid = train_test_split(X_train1,y_train1,test_size= t,random_state=0 )\n",
    "    svclassifier = SVC(kernel='rbf',gamma=0.0001,C=100)\n",
    "    svclassifier.fit(X_train,y_train)\n",
    "    y_pred = svclassifier.predict(X_test)\n",
    "    print(\"train size= \",round(1-(2*t),2))\n",
    "    print('Real y values: ',y_test)\n",
    "    print('Predicted y values: ',y_pred)\n",
    "    print('Confusion Matrix: ')\n",
    "    print(confusion_matrix(y_test,y_pred))\n",
    "    print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the results we obtain the fact that increasing the size of the train set from 0.1 up to 0.7 improves the accuracy,precision,recall,and F1 scores and decreases the number of falsely predicted labels in the confusion matrix. However, increasing the size from 0.7 to 0.9 decreases the scores and increases the number of falsely predicted values in the confusion matrix which suggests that we may be witnessing an overfit. Overall, increasing the train set size improves the model's performance and increases the overall accuracy which is visible in the evaluation metrics as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last part,we are asked to perform Grid Search on svm with Gaussian kernel in order to find the best hyper parameters(and overall do hyper parameter tuning)and report the results.\n",
    "We'll use sklearn's model selection library and import GridSearchCV to perform the task.\n",
    "First,we should specify some values for the hyper parameters and store them in the param_grid array.GridSearchCV will use this array to search in our specified values and fit svm on the train set trying different hyper parameter values and will calculate the accuracy score and in the end,it shall report the best hyper parameter values for our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see the effect of Grid Search more clearly,first we'll fit svm on the train set without hyper parameter tuning, predict the results using the test set and calculate the evaluation metrics. We'll then repeat the process using GridSearchCV and compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real y values:  [1 2 2 1 1 2 2 2 2 2 1 1 2 1 1 2 1 2]\n",
      "Predicted y values:  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "Confusion Matrix: \n",
      "[[ 0  8]\n",
      " [ 0 10]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         8\n",
      "           2       0.56      1.00      0.71        10\n",
      "\n",
      "    accuracy                           0.56        18\n",
      "   macro avg       0.28      0.50      0.36        18\n",
      "weighted avg       0.31      0.56      0.40        18\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train1, X_test, y_train1, y_test = train_test_split(x, y, test_size=0.15, random_state=0)\n",
    "X_train,X_valid,y_train,y_valid = train_test_split(X_train1,y_train1,test_size=0.15,random_state=0 )\n",
    "svclassifier = SVC(kernel='rbf')\n",
    "svclassifier.fit(X_train,y_train)\n",
    "y_pred = svclassifier.predict(X_test)\n",
    "print('Real y values: ',y_test)\n",
    "print('Predicted y values: ',y_pred)\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that in the confusion matrix we have 10 correctly predicted lables and 8 falsely predicted labels. The accuracy score is 0.56,precision is 0.28,recall is 0.5,and F1 score is 0.36.\n",
    "Let's see if we can improve the scores using Grid Search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we'll specify some C and gamma values(which are the only hyper parameters in the rbf kernel) and set our kernel type to rbf:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'C': [0.1,1.0, 10, 100, 1000],'gamma': [1,0.1,0.01,0.001,0.0001] ,'kernel': ['rbf']} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll call GridSearchCV and pass the param_grid array to it,set the number of cross validation folds to 6,then fit the grid search to the train set,and finally report the best hyper parameter values for our rbf model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma=0.0001, kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "grid = GridSearchCV(SVC(),param_grid,refit=True,cv=6)\n",
    "grid.fit(X_train,y_train)\n",
    "grid.best_params_\n",
    "print(grid.best_params_)\n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that the best C value found by Grid Search is 100 and the best gamma value is 0.0001.\n",
    "To test that and see if our model accuracy improves, we'll fit the tuned grid model with the best found hyper parameters on the test set,then we'll calculate the evaluation metrics and see if our result has improved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real y values:  [1 2 2 1 1 2 2 2 2 2 1 1 2 1 1 2 1 2]\n",
      "Predicted y values:  [1 2 2 1 1 1 2 2 2 2 1 2 2 1 1 2 1 1]\n",
      "Confusion Matrix: \n",
      "[[7 1]\n",
      " [2 8]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.88      0.82         8\n",
      "           2       0.89      0.80      0.84        10\n",
      "\n",
      "    accuracy                           0.83        18\n",
      "   macro avg       0.83      0.84      0.83        18\n",
      "weighted avg       0.84      0.83      0.83        18\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_grid = grid.predict(X_test)\n",
    "print('Real y values: ',y_test)\n",
    "print('Predicted y values: ',y_grid)\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix(y_test,y_grid))\n",
    "print(classification_report(y_test,y_grid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the results we can see that the confusion matrix now has 15 correct predictions and only 3 labels are predicted falsely. We have achieved an accuracy score of 0.83,precision of 0.83,recall of 0.84,and F1 score of 0.83 and so, the evaluation results confirm that Grid Search has indeed found the best hyper parameter values for Gaussian kernel(C=100 and gamma=0.0001) and the model performance has improved."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
